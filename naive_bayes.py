import numpy as np
import pandas as pd
import data_plotter as dp
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score, classification_report
from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import cross_validate, cross_val_score


def clean_data(filename):
    # create a data frame with pandas
    df = pd.read_table(filename, sep='\t', header=None, names=['label', 'features'])
    # convert the labels from strings to binary values
    # df['label'] = df.label.map({'safeware': 0, 'malware': 1})
    # df.label[df.label != 'safeware'] = 'malware'
    df.label[df.label != 'safeware'] = 1
    df.label[df.label == 'safeware'] = 0
    # removes all NaN values
    df = df.fillna('')
    # convert all characters in the message to lower case
    # df['features'] = df.features.map(lambda x: x.lower())
    # remove any punctuation
    # df['features'] = df.features.str.replace('[^\w\s]', '')

    # transform the data into occurrences,
    # which will be the features that we will feed into the model
    count_vect = CountVectorizer()
    counts = count_vect.fit_transform(df['features'])

    return df, counts


def train(X, y):
    # x_train, x_test, y_train, y_test = train_test_split(counts, list(df['label']), test_size=0.1, random_state=69)
    # model = MultinomialNB().fit(X, y)
    return MultinomialNB().fit(X, y)


def validation(X, y):
    kfold = KFold(10, True, 1)
    s_kfold = StratifiedKFold(10, True, 1)
    model = MultinomialNB()
    acc_scores = cross_val_score(model, X, y, cv=s_kfold)
    prec_scores = cross_val_score(model, X, y, scoring='precision', cv=s_kfold)
    recall_scores = cross_val_score(model, X, y, scoring='recall', cv=s_kfold)
    f1_scores = cross_val_score(model, X, y, scoring='f1', cv=s_kfold)
    plot(X, y, s_kfold)
    return np.mean(acc_scores), np.mean(prec_scores), np.mean(recall_scores), np.mean(f1_scores)

    # accuracy_scores, precision_scores, recall_scores, f_scores = [], [], [], []
    # for train_index, test_index in kfold.split(X):
    #     # split dataset for training and validation
    #     X_train, X_test = X[train_index], X[test_index]
    #     y_train, y_test = y[train_index], y[test_index]
    #
    #     # train
    #     model = train(X_train, y_train)
    #     # get predicted results
    #     y_predicted = model.predict(X_test)
    #     # calculate scores for local iteration
    #     accuracy_scores.append(accuracy_score(y_test, y_predicted))
    #     precision_scores.append(precision_score(y_test, y_predicted, average='binary', pos_label=1))
    #     recall_scores.append(recall_score(y_test, y_predicted, average='binary', pos_label=1))
    #     f_scores.append(fbeta_score(y_test, y_predicted, average='binary', pos_label=1, beta=1))
    # return np.mean(accuracy_scores), np.mean(precision_scores), np.mean(recall_scores), np.mean(f_scores)



def plot(X, y, kfold):
    title = "Learning Curves (Naive Bayes)"
    # Cross validation with 100 iterations to get smoother mean test and train
    # score curves, each time with 20% data randomly selected as a validation set.
    estimator = MultinomialNB()
    dp.plot_learning_curve(estimator, title, X, y, ylim=(0.7, 1.01), cv=kfold, n_jobs=4)
    plt.show()