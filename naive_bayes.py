import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score
from sklearn.model_selection import KFold
from sklearn.naive_bayes import MultinomialNB


def clean_data(filename):
    # create a data frame with pandas
    df = pd.read_table(filename, sep='\t', header=None, names=['label', 'features'])
    # convert the labels from strings to binary values
    # df['label'] = df.label.map({'safeware': 0, 'malware': 1})
    df.label[df.label != 'safeware'] = 1
    df.label[df.label == 'safeware'] = 0
    # removes all NaN values
    df = df.fillna('')
    # convert all characters in the message to lower case
    df['features'] = df.features.map(lambda x: x.lower())
    # remove any punctuation
    df['features'] = df.features.str.replace('[^\w\s]', '')
    # This converts the list of words into space-separated strings
    # df['features'] = df['features'].apply(lambda x: ''.join(x))

    # transform the data into occurrences,
    # which will be the features that we will feed into the model
    count_vect = CountVectorizer()
    counts = count_vect.fit_transform(df['features'])

    # Term Frequency Inverse Document Frequency, tf-idf
    # transformer = TfidfTransformer().fit(counts)
    # counts = transformer.transform(counts)
    return df, counts


def train(X, y):
    # x_train, x_test, y_train, y_test = train_test_split(counts, list(df['label']), test_size=0.1, random_state=69)
    # model = MultinomialNB().fit(X, y)
    return MultinomialNB().fit(X, y)


def validation(X, y):
    accuracy_scores, precision_scores, recall_scores, f_scores = [], [], [], []

    kfold = KFold(10, True, 1)
    for train_index, test_index in kfold.split(X):
        # split dataset for training and validation
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        # train
        model = MultinomialNB().fit(X_train, y_train)
        # get predicted results
        y_predicted = model.predict(X_test)
        # calculate scores for local iteration
        accuracy_scores.append(accuracy_score(y_test, y_predicted))
        precision_scores.append(precision_score(y_test, y_predicted, average='binary', pos_label=0))
        recall_scores.append(recall_score(y_test, y_predicted, average='binary', pos_label=0))
        f_scores.append(fbeta_score(y_test, y_predicted, average='binary', pos_label=0, beta=1))

    return np.mean(accuracy_scores), np.mean(precision_scores), np.mean(recall_scores), np.mean(f_scores)
