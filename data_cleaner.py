import string

import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer


def clean_data_linear(filename):
    df = create_df(filename)
    # convert the labels from strings to binary values
    df.labels[df.labels != 'safeware'] = 1
    df.labels[df.labels == 'safeware'] = 0
    # balance dataset
    fracs = {0: 1 / 10, 1: 1 / 10}
    df_balanced = balance_df(df, fracs)
    print(df_balanced.groupby('labels').describe())
    # clean text
    df_balanced['features'] = df_balanced['features'].apply(text_process)
    # Transform features collumn for one hot encoding
    df_balanced = df_balanced.drop('features', 1).join(df_balanced.features.str.join('|').str.get_dummies())
    df_balanced['labels'] = df_balanced['labels'].astype('int')
    return df_balanced.drop('labels', axis=1), np.array(df_balanced['labels'])


def clean_data_linear_family(filename):
    df = create_df(filename)
    # removes non malware
    df = df[df.labels != 'safeware']
    print(df.groupby('labels').describe())
    # clean text
    df['features'] = df['features'].apply(text_process)
    # Transform features collumn for one hot encoding
    df_balanced = df.drop('features', 1).join(df.features.str.join('|').str.get_dummies())
    df_balanced['labels'] = df_balanced['labels']
    return df_balanced.drop('labels', axis=1), np.array(df_balanced['labels'])


def clean_data_bayes(filename):
    df = create_df(filename)
    # convert the labels from strings to binary values
    df.labels[df.labels != 'safeware'] = 1
    df.labels[df.labels == 'safeware'] = 0
    # balance dataset
    fracs = {0: 1 / 5, 1: 1 / 5}
    df_balanced = balance_df(df, fracs)
    df_balanced['labels'] = df_balanced['labels'].astype('int')
    # clean text
    # df_balanced['features'] = df_balanced['features'].apply(text_process)
    # print(df_balanced.groupby('labels').describe())
    # transform the data into occurrences,
    # which will be the features that we will feed into the model
    count_vect = CountVectorizer(analyzer=text_process)
    counts = count_vect.fit_transform(df_balanced['features'])
    return counts, np.array(df_balanced['labels'])


def clean_data_bayes_family(filename):
    df = create_df(filename)
    # removes non malware
    df = df[df.labels != 'safeware']
    # clean text
    # df_balanced['features'] = df_balanced['features'].apply(text_process)
    # print(df_balanced.groupby('labels').describe())
    # transform the data into occurrences,
    # which will be the features that we will feed into the model
    count_vect = CountVectorizer(analyzer=text_process)
    counts = count_vect.fit_transform(df['features'])
    return counts, np.array(df['labels'])


def create_df(filename):
    # create a data frame with pandas
    df = pd.read_table(filename, sep='\t', header=None, names=['labels', 'features'])
    # removes all NaN values
    df = df.dropna()
    return df


def balance_df(df, fracs):
    # df_balanced = df.groupby('labels')
    # df_balanced = pd.DataFrame(df_balanced.apply(lambda x: x.sample(df_balanced.size().min()).reset_index(drop=True)))
    rand = np.random.RandomState([42])
    return pd.concat(
        dff.sample(n=int(fracs.get(i) * len(df)), replace=True, random_state=rand) for i, dff in df.groupby('labels'))


def text_process(mess):
    # Check characters to see if they are in punctuation
    nopunc = [char for char in mess if char not in string.punctuation]
    # Join the characters again to form the string.
    nopunc = ''.join(nopunc)
    # Remove any stopwords
    return nopunc.split()
