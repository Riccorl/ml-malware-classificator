{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlsplit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score, classification_report, make_scorer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Constants\n",
    "# feature, S1: Hardware components\n",
    "S1 = 'S1'\n",
    "# permission, S2: Requested permission\n",
    "S2 = 'S2'\n",
    "# activity, service_receiver, provider, service, S3: App Components\n",
    "S3 = 'S3'\n",
    "# intent, S4: Filtered Intents\n",
    "S4 = 'S4'\n",
    "# api_call, S5: Restricted API calls\n",
    "S5 = 'S5'\n",
    "# real_permission, S6: Used permission\n",
    "S6 = 'S6'\n",
    "# call, S7: Suspicious API calls\n",
    "S7 = 'S7'\n",
    "# url, S8: Network addresses\n",
    "S8 = 'S8'\n",
    "# files\n",
    "FAMILY_FILENAME = 'sha256_family.csv'\n",
    "DATASET_FILENAME = 'malware_dataset.csv'\n",
    "DATASET_NAIVE_FILENAME = 'naive_dataset.txt'\n",
    "FEATURES = 'feature_vectors'\n",
    "STATE = 'state.json'\n",
    "# dataset size\n",
    "SMALL_DATA = 'small_drebin'\n",
    "MEDIUM_DATA = 'medium_drebin'\n",
    "BIG_DATA = 'drebin'\n",
    "\n",
    "MANIFEST_DICT = {\n",
    "    S1: 'feature',\n",
    "    S2: 'permission',\n",
    "    S3: ['activity', 'service_receiver', 'provider', 'service'],\n",
    "    S4: 'intent',\n",
    "    S5: 'api_call',\n",
    "    S6: 'real_permission',\n",
    "    S7: 'call',\n",
    "    S8: 'url',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generation...\n",
      "Dataset exists\n",
      "Dataset is consistent, the generation of a new dataset will be skipped\n",
      "Dataset generation completed.\n"
     ]
    }
   ],
   "source": [
    "def generate_data_bayes(path, features_list):\n",
    "    family_file = os.path.join(path, FAMILY_FILENAME)\n",
    "    dataset_path = os.path.join(path, DATASET_NAIVE_FILENAME)\n",
    "    feature_path = os.path.join(path, FEATURES)\n",
    "    dataset_file = Path(dataset_path)\n",
    "    state_file = Path(STATE)\n",
    "\n",
    "    if dataset_file.exists() and state_file.exists():\n",
    "        print('Dataset exists')\n",
    "        with open('state.json') as f:\n",
    "            state = json.load(f)\n",
    "            if state.get('features_list', []) == features_list:\n",
    "                print('Dataset is consistent, the generation of a new dataset will be skipped')\n",
    "                return dataset_path\n",
    "            else:\n",
    "                print('Dataset is incosistent, generating a new dataset...')\n",
    "\n",
    "    with open(state_file, 'w') as state_writer:\n",
    "        json.dump({'features_list': features_list}, state_writer)\n",
    "\n",
    "    with open(family_file) as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        next(reader, None)  # skip the headers\n",
    "        malware_dict = {rows[0]: rows[1] for rows in reader}\n",
    "\n",
    "    with open(dataset_path, mode='w') as dataset:\n",
    "        mainfest_subset = dict((k, MANIFEST_DICT[k]) for k in features_list if k in MANIFEST_DICT)\n",
    "        for file in os.listdir(feature_path):\n",
    "            label = malware_dict.get(file, \"safeware\")\n",
    "            feature = extract_feature_naive(os.path.join(feature_path, file), mainfest_subset)\n",
    "            dataset.write(label + '\\t' + feature + \"\\n\")\n",
    "\n",
    "    return dataset_path\n",
    "\n",
    "\n",
    "def extract_feature_naive(filename, features_dict):\n",
    "    feature = ''\n",
    "    with open(filename, mode='r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            splitted = re.split(':{2}', line)\n",
    "            if splitted[0] in features_dict.values():\n",
    "                feature = ' '.join([feature, extract(splitted[0], splitted[1])])\n",
    "\n",
    "    return feature[1:]\n",
    "\n",
    "def extract(category, feature):\n",
    "    switch = {\n",
    "        'feature':extract_feature,\n",
    "        'permission': extract_permission,\n",
    "        'activity': extract_activity,\n",
    "        'service_receiver': extract_service_receiver,\n",
    "        'provider': extract_provider,\n",
    "        'service': extract_service,\n",
    "        'intent': extract_intent,\n",
    "        'api_call': extract_api_call,\n",
    "        'real_permission': extract_permission,\n",
    "        'call': extract_call,\n",
    "        'url': extract_url\n",
    "    }\n",
    "    return switch[category](feature)\n",
    "\n",
    "def extract_url(string):\n",
    "    try:\n",
    "        base_url = \"{0.scheme}://{0.netloc}/\".format(urlsplit(string))\n",
    "        if len(base_url) > 10:\n",
    "            return base_url\n",
    "    except:\n",
    "        # print('Error html: ', string)\n",
    "        return None\n",
    "\n",
    "\n",
    "# Extract api_call\n",
    "def extract_api_call(string):\n",
    "    try:\n",
    "        string = string.replace(';->', '/')\n",
    "        # api_call = string.split('/')\n",
    "        return string.lower()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Extract feature\n",
    "def extract_feature(string):\n",
    "    try:\n",
    "        feature = string.split('.')[-1].lower()\n",
    "        return feature\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Extract permission and real_permission\n",
    "def extract_permission(string):\n",
    "    try:\n",
    "        permission = string.split('.')[-1].lower()\n",
    "        return permission\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Extract call\n",
    "def extract_call(string):\n",
    "    try:\n",
    "        call = string.lower()\n",
    "        return call\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Extract activity\n",
    "def extract_activity(string):\n",
    "    try:\n",
    "        activity = string.split('.')[-1].lower()\n",
    "        return activity\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Extract intent\n",
    "def extract_intent(string):\n",
    "    try:\n",
    "        intent = string.split('.')[-1].lower()\n",
    "        return intent\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Extract service_receiver\n",
    "def extract_service_receiver(string):\n",
    "    try:\n",
    "        service_receiver = string.split('.')[-1].lower()\n",
    "        return service_receiver\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Extract service_receiver\n",
    "def extract_service(string):\n",
    "    try:\n",
    "        return string.lower()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Extract provider\n",
    "def extract_provider(string):\n",
    "    try:\n",
    "        provider = string.split('.')[-1].lower()\n",
    "        return provider\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "print('Dataset generation...')\n",
    "filename = generate_data_bayes(BIG_DATA, [S5, S6, S7])\n",
    "print('Dataset generation completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    # Now just remove any stopwords\n",
    "    return nopunc.split()\n",
    "\n",
    "\n",
    "def clean_data(filename):\n",
    "    # create a data frame with pandas\n",
    "    df = pd.read_table(filename, sep='\\t', header=None, names=['label', 'features'])\n",
    "    # convert the labels from strings to binary values\n",
    "    df.label[df.label != 'safeware'] = 'malware'\n",
    "    # removes all NaN values\n",
    "    df = df.dropna()\n",
    "    # balance dataset\n",
    "    # df_balanced = df.groupby('label')\n",
    "    # df_balanced = pd.DataFrame(df_balanced.apply(lambda x: x.sample(df_balanced.size().min()).reset_index(drop=True)))\n",
    "    N = len(df)\n",
    "    fracs = {'safeware': 1/20, 'malware': 1/1}\n",
    "    df_balanced = pd.concat(df.sample(n=int(fracs.get(i) * N)) for i,dff in df.groupby('label'))\n",
    "    print(df_balanced['features'].head())\n",
    "    # clean text\n",
    "    df_balanced['features'] = df_balanced['features'].apply(text_process)\n",
    "    print(df_balanced['features'].head())\n",
    "    print(df_balanced.describe())\n",
    "    # transform the data into occurrences,\n",
    "    # which will be the features that we will feed into the model\n",
    "    count_vect = CountVectorizer(analyzer=text_process)\n",
    "    counts = count_vect.fit_transform(df_balanced['features'])\n",
    "\n",
    "    return df_balanced, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean the data set...\n",
      "4204                               sendsms getsystemservice\n",
      "7953      android/net/connectivitymanager/getactivenetwo...\n",
      "76263     getsubscriberid android/telephony/telephonyman...\n",
      "40642     getdeviceid org/apache/http/impl/client/defaul...\n",
      "121264    printstacktrace android/hardware/camera/open r...\n",
      "Name: features, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Clean the data set...')\n",
    "df, counts = clean_data(filename)\n",
    "print('Dataset cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(X, y):\n",
    "    kfold = KFold(10, True, 1)\n",
    "    s_kfold = StratifiedKFold(10, True, 1)\n",
    "    model = MultinomialNB()\n",
    "    acc_scores = cross_val_score(model, X, y, cv=s_kfold)\n",
    "    prec_scores = cross_val_score(model, X, y, scoring=make_scorer(precision_score, pos_label='malware'), cv=s_kfold)\n",
    "    recall_scores = cross_val_score(model, X, y, scoring=make_scorer(recall_score, pos_label='malware'), cv=s_kfold)\n",
    "    f1_scores = cross_val_score(model, X, y, scoring=make_scorer(fbeta_score, beta=1, pos_label='malware'), cv=s_kfold)\n",
    "    # plot(X, y, s_kfold)\n",
    "    return np.mean(acc_scores), np.mean(prec_scores), np.mean(recall_scores), np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and evaluation of the model...\n",
      "Accuracy: 0.9714116865711795\n",
      "Precision: 0.9912715129010339\n",
      "Recall: 0.36956970740103273\n",
      "F1 score: 0.5379421066417553\n"
     ]
    }
   ],
   "source": [
    "print('Train and evaluation of the model...')\n",
    "accuracy, precision, recall, fscore = validation(counts, np.array(df['label']))\n",
    "print('Accuracy: ' + repr(accuracy))\n",
    "print('Precision: ' + repr(precision))\n",
    "print('Recall: ' + repr(recall))\n",
    "print('F1 score: ' + repr(fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
